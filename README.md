
# 🎙️ Feple(피플): AI 기반 상담 분석 및 코칭 플랫폼

> **Feple은 콜센터의 품질 관리(QC) 및 상담사 코칭 프로세스를 100% 자동화하고, 데이터 기반의 객관적인 평가와 맞춤형 코칭을 제공하여 상담 품질과 관리 효율을 혁신하는 AI 솔루션입니다.**

- 기존의 주관적이고 샘플링에 의존했던 수동 평가 방식의 한계를 극복하고, 모든 상담 내용을 AI가 분석하여 일관성 있고 공정한 평가를 제공합니다.
- Feple은 단순한 분석 도구를 넘어, **AI 전환(AX)을 통해 콜센터 운영의 패러다임을 바꾸는 통합 플랫폼**입니다.

---

## 👥 **프로젝트를 만든 사람들**

| 이름 | 역할 | 주요 담당 업무 |
| :--- | :--- | :--- |
| **오현서** | 팀장, 백엔드 | 서버 환경 구축, 백엔드 API 연동, 웹 퍼블리싱 |
| **김기훈** | AI, 백엔드 | 5대 지표 산출 알고리즘 설계, 데이터 수집, 백엔드 API 연동 |
| **노준석** | 프론트엔드, 아키텍트 | 시스템 아키텍처 설계, 프론트엔드 총괄, Call 모델 고도화 |
| **오정우** | 기획, AI | 프로젝트 기획, Call 모델 개발, 사용자 경험(UX) 설계 |

---

## ✨ **실제 서비스 & 주요 기능**

> **🔗 [feple-ad.vercel.app](https://feple-ad.vercel.app)**

| 구분 | For Consultants (상담사) | For QC Managers (QC 관리자) |
| :--- | :--- | :--- |
| **성과 대시보드** | 개인의 성과 지표, 성장 추이, 강점/약점을 시각적으로 확인하고 동료와 비교하며 자기주도적 성장을 도모합니다. | 팀/부서별 전체 상담사의 성과를 실시간으로 모니터링하고, 우수 상담사와 코칭이 필요한 상담사를 즉시 파악합니다. |
| **AI 코칭 리포트** | 모든 상담콜에 대해 AI가 생성한 강점, 개선점, 구체적인 코칭 팁이 담긴 리포트를 즉시 제공받습니다. | 모든 평가 과정이 자동화되어, QC 관리자는 분석이 아닌 코칭과 품질 개선 전략 수립 등 고부가가치 업무에 집중할 수 있습니다. |
| **상세 분석** | 상담 스크립트 전체와 함께 감정 변화, 주요 지표(정중함, 공감 등) 점수를 상세히 검토하며 스스로 문제점을 진단합니다. | 특정 상담 세션을 드릴다운하여 문제의 근본 원인을 파악하고, 데이터에 기반한 객관적이고 공정한 피드백을 제공합니다. |
| **간편한 사용** | 상담 녹음 파일을 업로드하기만 하면, 전사부터 분석, 평가, 코칭까지 모든 과정이 자동으로 처리됩니다. | 수동으로 통화 내용을 듣고 평가하는 시간을 **95% 이상 단축**하고, 일관된 기준으로 팀 전체의 품질을 관리합니다. |

---

## 🌊 **데이터 흐름도 (Data Flow)**

- Feple의 데이터 처리 파이프라인은 상담 녹음 파일이 업로드되는 순간부터 최종 분석 리포트가 대시보드에 표시되기까지, 아래와 같이 체계적이고 자동화된 단계로 진행됩니다.

![Feple Data Flow](docs/Feple%20Data%20Flow.png)

---

## 🏛️ **기술 아키텍처 및 성능**

- Feple은 최신 서버리스 기술과 고성능 AI 모델을 결합하여, 확장성과 효율성, 그리고 기술적 깊이를 모두 갖춘 시스템을 구현했습니다.

### **인프라 아키텍처: 100% Serverless & MSA**

- 모든 인프라는 Vercel, Replicate, Supabase를 기반으로 한 **완전 서버리스(Fully Serverless)** 환경에 구축되었습니다.
- 각 컴포넌트는 독립적인 마이크로서비스로 동작하여, 트래픽 증가 시 자동 확장되고, 장애 발생 시 다른 서비스에 미치는 영향을 최소화합니다.

*   **Vercel (프론트엔드 & 엣지 컴퓨팅):** Next.js로 구축된 프론트엔드를 글로벌 엣지 네트워크에 배포하여 전 세계 어디서든 빠른 접속 속도를 보장하며, 서버리스 함수를 통해 백엔드 로직을 처리합니다.
*   **Replicate (서버리스 AI 추론):** `cog`로 컨테이너화된 Feple의 AI 모델을 배포하여, 복잡한 MLOps 없이 사용량에 따라 GPU 자원이 자동 할당/확장되는 비용 효율적인 AI 추론 환경을 구축했습니다.
*   **Supabase (통합 백엔드):** PostgreSQL DB, 파일 스토리지, 인증 등 백엔드의 모든 기능을 통합 제공하여 개발 및 운영의 복잡성을 크게 낮췄습니다.

### **성능 우수성**

> [`Feple 서비스 성능 평가 결과서`](docs/Feple%20서비스%20성능%20평가%20결과서.pdf)를 확인하여 알 수 있듯이, Feple은 모든 핵심 성능 지표(SLA)를 성공적으로 충족 및 초과 달성했습니다.

*   **준실시간 AI 분석:** 5분 길이의 상담 통화 파일을 **평균 49.7초** 만에 분석 완료합니다. (실제 통화 시간의 **16.7%** 수준)
*   **빠른 대시보드:** 대시보드 초기 로딩 **3초 이내**, 데이터 조회 **평균 5.2초**로 쾌적한 사용자 경험을 제공합니다.
*   **안정적인 API:** 50명의 사용자가 동시 접속하는 부하 테스트 환경에서도 95%의 요청을 **450ms** 이내에 처리하는 견고함을 입증했습니다.
*   **높은 처리 용량:** 완전 자동화된 파이프라인을 통해 **일일 10,000건 이상의 상담**을 처리할 수 있습니다.

---

## 🧠 **Hybrid AI & 한국어 특화된 AI 모델**

- Feple의 AI는 단순히 외부 API를 호출하는 것을 넘어, 속도와 정확도, 비용 효율성을 모두 고려한 **하이브리드(Hybrid) AI 아키텍처**로 설계되었습니다. 이는 [`모델 정의서`](docs/모델%20정의서/Feple%20CALL%20모델%20정의서.pdf)에 상세히 기술된 Feple의 핵심적인 설계 철학입니다.

### **왜 하이브리드 AI인가?**

*   **규칙 기반 접근의 역할:** '존댓말 어미'(-습니다, -세요)처럼 명확하고 반복적인 패턴은 규칙(Rule-based)으로 빠르게 처리하여 효율성을 극대화합니다. 이는 LLM의 불필요한 호출을 줄여 비용과 시간을 절약합니다.
*   **LLM 기반 접근의 역할:** '사과의 진정성'이나 '문제 해결 제안의 논리적 타당성'처럼 깊은 문맥 이해가 필요한 정성적 분석은 LLM을 통해 처리합니다.
*   **시너지:** 규칙 기반으로 1차 필터링을 거친 후, 정제된 후보군에 대해서만 LLM이 심층 분석을 수행하는 **'필터링 및 검증'** 역할을 통해, 전체 파이프라인의 속도, 정확도, 비용 효율성 간의 최적의 균형을 달성했습니다.

### **1. Feple_AI: 핵심 분석 엔진**

*   **STT (음성 인식):** `faster-whisper` (medium 모델)를 채택하여 빠르고 정확한 한국어 음성 인식을 수행합니다.
*   **화자 분리:** `pyannote/speaker-diarization-3.1` 모델을 통해 상담사와 고객의 발화를 95% 이상의 정확도로 분리합니다. (현재 시스템의 주된 병목점으로, 향후 성능 개선의 핵심 포인트)
*   **한국어 특화 NLP:** `Kiwipiepy` (형태소 분석), `KSS` (문장 분리) 라이브러리를 사용하여 존댓말, 완곡어법 등 한국어의 미묘한 뉘앙스까지 정확하게 분석합니다.
*   **18개의 다각적 분석 지표:** 아래와 같이 다각적인 지표를 추출하여 상담 품질을 입체적으로 분석합니다.
    *   **정중함 및 언어 품질:** 존댓말 사용률, 긍/부정어 비율, 완곡어 사용률
    *   **공감적 소통:** 공감/사과 표현의 진정성 (LLM으로 검증)
    *   **문제 해결 역량:** 구체적인 해결책 제시 수준
    *   **감정 안정성:** 상담 전후 고객 감정 변화 추이
    *   **대화 흐름 및 응대 태도:** 평균 응답 시간, 끼어들기, 침묵 비율

### **2. Feple_LLM_Algorithm: 자동 피드백/코칭 생성**

*   **객관적 점수화:** `Feple_AI`가 추출한 18개 지표를 바탕으로, 사전에 정의된 `cutoff` 기준에 따라 5대 핵심 역량(정중함 및 언어 품질, 공감적 소통, 문제 해결 역량 등)의 점수와 등급을 계산합니다.
*   **LLM 기반 정성 피드백:** 이 점수/등급과 전체 스크립트를 **OpenAI의 GPT** 모델에 전달하여, 단순 평가를 넘어 구체적인 **강점, 개선점, 실천 가능한 코칭 멘트**를 생성합니다.
*   **완전 자동화 파이프라인:** Supabase DB를 폴링(polling)하여 새로운 분석 데이터가 입수되는 즉시, 점수화부터 LLM 리포트 생성, 결과 저장까지의 모든 과정을 자동으로 수행합니다.

---

## 💻 **핵심 코드**

- Feple의 핵심 기능이 어떻게 코드로 구현되었는지 간략하게 알려드리겠습니다.

### **`Feple_AD` - 동적 차트 생성 (in `ScoreChart.tsx`)**
- *Recharts 라이브러리를 사용하여 AI 분석 결과를 바탕으로 동적인 레이더 차트를 생성하고, 상담사의 역량을 시각적으로 보여주는 핵심 컴포넌트입니다.*

<img width="3960" height="1876" alt="carbon (3)" src="https://github.com/user-attachments/assets/b5d9ca6a-6116-47ca-ac08-89e3a6e451d6" />

### **`Feple_AI` - AI 분석 파이프라인 (in `pipeline.py`)**
- *오디오 파일이 입력되었을 때, 화자 분리, STT, 지표 계산 등 전체 AI 분석 프로세스를 순차적으로 실행하고 결과를 종합하는 파이프라인의 중심부입니다.*

<img width="3960" height="2024" alt="carbon (4)" src="https://github.com/user-attachments/assets/94086d96-df04-476d-b375-91e734b433f9" />

### **`Feple_LLM_Algorithm` - 자동화된 LLM 피드백 생성 (in `LLM_evaluation_with_supabase.py`)**
- *Supabase DB를 주기적으로 확인하여, 처리되지 않은 분석 결과가 있으면 자동으로 점수를 매기고 LLM을 호출하여 코칭 피드백을 생성한 뒤, 다시 DB에 저장하는 완전 자동화 로직의 핵심입니다.*

<img width="3960" height="2176" alt="carbon (5)" src="https://github.com/user-attachments/assets/d65884df-1a66-4513-8c25-8599316059a0" />

---

## 🚀 **시작하기**

### **사전 요구사항**

*   Node.js 18+
*   Python 3.10+
*   Supabase 프로젝트 생성 및 API 키 발급
*   OpenAI API 키 발급
*   Replicate 계정 및 API 토큰 발급

### **설치 및 실행**

1.  **저장소 클론 (서브모듈 포함):**
    ```bash
    git clone --recurse-submodules https://github.com/your-repo/Feple_v2.git
    cd Feple_v2
    ```
2.  **Feple_AD (프론트엔드) 설정:**
    ```bash
    cd Feple_AD
    npm install
    # .env.local 파일에 Supabase 및 기타 환경변수 설정
    npm run dev
    ```
3.  **Feple_AI (AI 모델) 배포:**
    ```bash
    cd ../Feple_AI
    # Replicate CLI 설치 및 로그인
    cog push r8.im/your-username/feple-ai
    ```
4.  **Feple_LLM_Algorithm (피드백 생성) 실행:**
    ```bash
    cd ../Feple_LLM_Algorithm
    pip install -r requirements.txt
    # .env 파일에 Supabase, OpenAI 환경변수 설정
    python LLM_evaluation_with_supabase.py
    ```

---

## 📂 **프로젝트 문서 안내**

- 프로젝트에 대한 더 깊이 있는 정보는 아래 `docs` 폴더의 문서를 참고해 주세요. (문서명을 클릭하면 해당 파일로 이동합니다.)

| 문서명 | 주요 내용 |
| :--- | :--- |
| [**Feple 프로젝트 계획서.pdf**](docs/Feple%20프로젝트%20계획서.pdf) | 프로젝트의 범위, 리소스 계획을 담고 있는 문서입니다. |
| [**Feple 요구사항정의서.xlsx**](docs/Feple%20요구사항정의서.xlsx) | 프로젝트 초기 단계에 정의된 시스템의 기능적/비기능적 요구사항 명세서입니다. |
| [**Feple WBS.xlsx**](docs/Feple%20WBS.xlsx) | 프로젝트의 전체 작업을 상세하게 분할한 WBS입니다. |
| [**모델 정의서/Feple CALL 모델 정의서.pdf**](docs/모델%20정의서/Feple%20CALL%20모델%20정의서.pdf) | Feple AI 모델의 하이브리드 아키텍처, 각 기술 스택의 선정 근거, 18개 세부 분석 지표의 상세 계산 방식 등 모델의 핵심 설계 사상을 심도 있게 다룹니다. |
| [**모델 정의서/Feple LLM Alogorithm 모델 정의서.pdf**](docs/모델%20정의서/Feple%20LLM%20Alogorithm%20모델%20정의서.pdf) | 5대 지표 산출을 바탕으로 강점, 개선점, 코칭 멘트 생성 과정에 대해 다룹니다. |
| [**Feple 서비스 성능 평가 결과서.pdf**](docs/Feple%20서비스%20성능%20평가%20결과서.pdf) | AI 파이프라인 및 대시보드의 상세 성능(처리 속도, 응답 시간 등) 측정 결과와 분석, 병목 현상 및 개선 제안을 확인할 수 있습니다. |
| [**Feple 프로젝트 수행 결과 보고서.pdf**](docs/Feple%20프로젝트%20수행%20결과%20보고서.pdf) | 프로젝트 계획 대비 실제 수행 결과를 비교하고, 성과와 교훈을 정리한 최종 보고서입니다. |
| [**Feple 최종 발표 자료.pdf**](docs/Feple%20최종%20발표%20자료.pdf) | 프로젝트의 배경, 목표, 개발 과정, 시연, 기대 효과를 요약한 최종 발표 자료입니다. |

---

## 🖼️ **스크린샷**

| 구분 | 실제 화면 |
| :---: | :---: |
| 상담사 대시보드 | <img width="1919" height="878" alt="image" src="https://github.com/user-attachments/assets/8f9e6d78-1aac-4ef5-a2d0-95becef2f7f3" /> |
| 상담사 모니터링 | <img width="1919" height="879" alt="image" src="https://github.com/user-attachments/assets/05247edd-9657-45dd-90b9-c81aa0c87425" /> |
| QC 관리자 대시보드 | <img width="1919" height="878" alt="image" src="https://github.com/user-attachments/assets/ba6cd5d8-4663-433e-b5d7-99fb7d9cc750" /> |
| QC 관리자 모니터링 | <img width="1919" height="880" alt="image" src="https://github.com/user-attachments/assets/7a63d15a-c187-4532-9924-81b51e2ba368" /> |
